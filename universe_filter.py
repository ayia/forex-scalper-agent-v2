"""\nUniverse Filter Module\n======================\nFilters trading pairs based on spread, volatility, and news events.\n"""\nimport pandas as pd\nimport pandas_ta as ta\nfrom typing import List, Dict, Optional\nfrom datetime import datetime, timedelta\nimport requests\nfrom bs4 import BeautifulSoup\nfrom loguru import logger\n\nfrom config import ALL_PAIRS, RISK_PARAMS, get_pip_value\nfrom data_fetcher import data_fetcher\n\n\nclass UniverseFilter:\n    """\n    Filters the trading universe to only tradable pairs.\n    """\n    \n    def __init__(self):\n        self.max_spread = RISK_PARAMS["max_spread_pips"]\n        self.min_atr = RISK_PARAMS["min_atr_pips"]\n        self.max_atr = RISK_PARAMS["max_atr_pips"]\n        self.news_window = RISK_PARAMS["news_filter_minutes"]\n        self._news_cache = {}\n        self._news_cache_time = None\n    \n    def filter_by_spread(\n        self, \n        pairs: List[str], \n        max_spread: Optional[float] = None\n    ) -> List[str]:\n        """\n        Filter pairs by maximum spread.\n        \n        Args:\n            pairs: List of pairs to filter\n            max_spread: Maximum spread in pips (uses config default if None)\n        \n        Returns:\n            List of pairs with acceptable spread\n        """\n        max_spread = max_spread or self.max_spread\n        filtered = []\n        \n        for pair in pairs:\n            price_data = data_fetcher.get_current_price(pair)\n            if price_data:\n                pip_value = get_pip_value(pair)\n                spread_pips = price_data["spread"] / pip_value\n                \n                if spread_pips <= max_spread:\n                    filtered.append(pair)\n                    logger.debug(f"{pair}: Spread {spread_pips:.1f} pips - PASS")\n                else:\n                    logger.debug(f"{pair}: Spread {spread_pips:.1f} pips - REJECT")\n        \n        return filtered\n    \n    def filter_by_volatility(\n        self, \n        pairs: List[str],\n        min_atr: Optional[float] = None,\n        max_atr: Optional[float] = None\n    ) -> List[str]:\n        """\n        Filter pairs by ATR volatility range.\n        \n        Args:\n            pairs: List of pairs to filter\n            min_atr: Minimum ATR in pips\n            max_atr: Maximum ATR in pips\n        \n        Returns:\n            List of pairs within volatility range\n        """\n        min_atr = min_atr or self.min_atr\n        max_atr = max_atr or self.max_atr\n        filtered = []\n        \n        for pair in pairs:\n            df = data_fetcher.fetch_live_data(pair, "M5", bars=50)\n            if df is not None and len(df) >= 14:\n                atr = ta.atr(df["high"], df["low"], df["close"], length=14)\n                if atr is not None and len(atr) > 0:\n                    current_atr = atr.iloc[-1]\n                    pip_value = get_pip_value(pair)\n                    atr_pips = current_atr / pip_value\n                    \n                    if min_atr <= atr_pips <= max_atr:\n                        filtered.append(pair)\n                        logger.debug(f"{pair}: ATR {atr_pips:.1f} pips - PASS")\n                    else:\n                        logger.debug(f"{pair}: ATR {atr_pips:.1f} pips - REJECT")\n        \n        return filtered\n    \n    def _fetch_news_calendar(self) -> Dict[str, List[Dict]]:\n        """\n        Fetch economic calendar events (cached for 5 minutes).\n        \n        Returns:\n            Dict mapping currency codes to list of events\n        """\n        now = datetime.utcnow()\n        if (self._news_cache_time and \n            (now - self._news_cache_time).seconds < 300):\n            return self._news_cache\n        \n        try:\n            # Scrape ForexFactory calendar (simplified)\n            url = "https://www.forexfactory.com/calendar"\n            headers = {"User-Agent": "Mozilla/5.0"}\n            response = requests.get(url, headers=headers, timeout=10)\n            \n            events = {}\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, "lxml")\n                # Parse events (simplified - in production use proper parsing)\n                for currency in ["USD", "EUR", "GBP", "JPY", "AUD", "CAD", "CHF", "NZD"]:\n                    events[currency] = []\n            \n            self._news_cache = events\n            self._news_cache_time = now\n            logger.info("News calendar updated")\n        \n        except Exception as e:\n            logger.error(f"Failed to fetch news calendar: {e}")\n            # Return empty cache on error\n            self._news_cache = {}\n        \n        return self._news_cache\n    \n    def filter_by_news_calendar(\n        self, \n        pairs: List[str],\n        time_window: Optional[int] = None\n    ) -> List[str]:\n        """\n        Filter out pairs with high-impact news in the specified window.\n        \n        Args:\n            pairs: List of pairs to filter\n            time_window: Minutes before/after news to exclude\n        \n        Returns:\n            List of pairs without imminent high-impact news\n        """\n        time_window = time_window or self.news_window\n        news_events = self._fetch_news_calendar()\n        \n        filtered = []\n        for pair in pairs:\n            # Extract currencies from pair (e.g., EURUSD -> EUR, USD)\n            base = pair[:3]\n            quote = pair[3:]\n            \n            base_news = news_events.get(base, [])\n            quote_news = news_events.get(quote, [])\n            \n            # Check if any high-impact news within window\n            has_news = False\n            for event in base_news + quote_news:\n                if event.get("impact") == "high":\n                    event_time = event.get("time")\n                    if event_time:\n                        # Check if within window\n                        now = datetime.utcnow()\n                        if abs((event_time - now).total_seconds()) < time_window * 60:\n                            has_news = True\n                            break\n            \n            if not has_news:\n                filtered.append(pair)\n                logger.debug(f"{pair}: No high-impact news - PASS")\n            else:\n                logger.debug(f"{pair}: High-impact news imminent - REJECT")\n        \n        return filtered\n    \n    def get_tradable_universe(self) -> List[str]:\n        """\n        Apply all filters to get the current tradable universe.\n        \n        Returns:\n            List of pairs that pass all filters\n        """\n        logger.info(f"Starting universe filter with {len(ALL_PAIRS)} pairs")\n        \n        # Apply filters sequentially\n        pairs = ALL_PAIRS.copy()\n        \n        # 1. Spread filter\n        pairs = self.filter_by_spread(pairs)\n        logger.info(f"After spread filter: {len(pairs)} pairs")\n        \n        # 2. Volatility filter\n        pairs = self.filter_by_volatility(pairs)\n        logger.info(f"After volatility filter: {len(pairs)} pairs")\n        \n        # 3. News filter\n        pairs = self.filter_by_news_calendar(pairs)\n        logger.info(f"After news filter: {len(pairs)} pairs")\n        \n        logger.info(f"Final tradable universe: {pairs}")\n        return pairs\n\n\n# Singleton instance\nuniverse_filter = UniverseFilter()
